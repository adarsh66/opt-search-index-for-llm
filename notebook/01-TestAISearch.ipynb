{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add AI Search to your RAG solution\n",
    "This notebook will have the following two components:\n",
    "1. How to build AI Search components using the REST api\n",
    "2. How to test the quality and latency of RAG output using Azure OpenAI GPT-4 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. How to build AI Search components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import uuid\n",
    "import logging\n",
    "\n",
    "\n",
    "class AISearchIndexer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        search_service,\n",
    "        data_source_name,\n",
    "        search_index_name,\n",
    "        vector_index_name,\n",
    "        indexer_name,\n",
    "        vector_skillset_name,\n",
    "        api_key,\n",
    "        api_version=\"2023-10-01-Preview\",\n",
    "    ):\n",
    "        self.search_service = search_service\n",
    "        self.data_source_name = data_source_name\n",
    "        self.search_index_name = search_index_name\n",
    "        self.vector_index_name = vector_index_name\n",
    "        self.indexer_name = indexer_name\n",
    "        self.vector_skillset_name = vector_skillset_name\n",
    "        self.api_key = api_key\n",
    "        self.api_version = api_version\n",
    "        self.headers = {\"Content-Type\": \"application/json\", \"api-key\": self.api_key}\n",
    "        self.max_service_name_size = 28\n",
    "        self.vector_search_profile = self.generate_service_name(\"vector-profile\")\n",
    "        self.vector_search_config = self.generate_service_name(\"vector-search-config\")\n",
    "        self.vector_search_vectorizer = self.generate_service_name(\"vectorizer\")\n",
    "        self.semantic_config = self.generate_service_name(\"semantic-config\")\n",
    "\n",
    "    def generate_service_name(self, service_name_prefix):\n",
    "        # Generate a UUID\n",
    "        uuid_str = str(uuid.uuid4())\n",
    "\n",
    "        # Concatenate the prefix and the UUID\n",
    "        service_name = service_name_prefix + \"-\" + uuid_str\n",
    "\n",
    "        # Truncate the service name to the maximum size if necessary\n",
    "        if len(service_name) > self.max_service_name_size:\n",
    "            service_name = service_name[: self.max_service_name_size]\n",
    "\n",
    "        return service_name\n",
    "\n",
    "    def create_data_source_blob_storage(\n",
    "        self, blob_connection, blob_container_name, query\n",
    "    ):\n",
    "        data_source_payload = {\n",
    "            \"name\": self.data_source_name,\n",
    "            \"description\": \"Data source for Azure Blob storage container\",\n",
    "            \"type\": \"azureblob\",\n",
    "            \"credentials\": {\"connectionString\": blob_connection},\n",
    "            \"container\": {\"name\": blob_container_name, \"query\": query},\n",
    "            \"dataChangeDetectionPolicy\": None,\n",
    "            \"dataDeletionDetectionPolicy\": {\n",
    "                \"@odata.type\": \"#Microsoft.Azure.Search.NativeBlobSoftDeleteDeletionDetectionPolicy\"\n",
    "            },\n",
    "        }\n",
    "        response = requests.post(\n",
    "            f\"https://{self.search_service}.search.windows.net/datasources?api-version={self.api_version}\",\n",
    "            headers=self.headers,\n",
    "            json=data_source_payload,\n",
    "        )\n",
    "        if response.status_code == 201:\n",
    "            self.data_source = response.json()\n",
    "            return True\n",
    "        else:\n",
    "            logging.error(f\"{response.status_code} || {response.json()}\")\n",
    "            return False\n",
    "\n",
    "    def check_data_source_exists(self):\n",
    "        response = requests.get(\n",
    "            f\"https://{self.search_service}.search.windows.net/datasources('{self.data_source_name}')?api-version={self.api_version}\",\n",
    "            headers=self.headers,\n",
    "        )\n",
    "        return response.status_code == 200\n",
    "\n",
    "    def check_index_exists(self, index_name):\n",
    "        response = requests.get(\n",
    "            f\"https://{self.search_service}.search.windows.net/indexes('{index_name}')?api-version={self.api_version}\",\n",
    "            headers=self.headers,\n",
    "        )\n",
    "        return response.status_code == 200\n",
    "\n",
    "    def create_search_index_payload(self):\n",
    "        index_payload = {\n",
    "            \"name\": self.search_index_name,\n",
    "            \"fields\": [\n",
    "                {\n",
    "                    \"name\": \"id\",\n",
    "                    \"type\": \"Edm.String\",\n",
    "                    \"key\": True,\n",
    "                    \"searchable\": True,\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"content\",\n",
    "                    \"type\": \"Edm.String\",\n",
    "                    \"retrievable\": True,\n",
    "                    \"searchable\": True,\n",
    "                    \"filterable\": False,\n",
    "                    \"sortable\": False,\n",
    "                    \"facetable\": False,\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"metadata_storage_path\",\n",
    "                    \"type\": \"Edm.String\",\n",
    "                    \"retrievable\": True,\n",
    "                    \"searchable\": False,\n",
    "                    \"filterable\": True,\n",
    "                    \"sortable\": False,\n",
    "                    \"facetable\": False,\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"metadata_storage_name\",\n",
    "                    \"type\": \"Edm.String\",\n",
    "                    \"searchable\": False,\n",
    "                    \"filterable\": True,\n",
    "                    \"sortable\": True,\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"metadata_storage_size\",\n",
    "                    \"type\": \"Edm.Int64\",\n",
    "                    \"searchable\": False,\n",
    "                    \"filterable\": True,\n",
    "                    \"sortable\": True,\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"metadata_storage_content_type\",\n",
    "                    \"type\": \"Edm.String\",\n",
    "                    \"searchable\": False,\n",
    "                    \"filterable\": True,\n",
    "                    \"sortable\": True,\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "        return index_payload\n",
    "\n",
    "    def create_vector_index_payload(\n",
    "        self, model_uri, model_name, model_api_key, embedding_dims\n",
    "    ):\n",
    "        index_payload = {\n",
    "            \"name\": self.vector_index_name,\n",
    "            \"defaultScoringProfile\": \"\",\n",
    "            \"fields\": [\n",
    "                {\n",
    "                    \"name\": \"id\",\n",
    "                    \"type\": \"Edm.String\",\n",
    "                    \"searchable\": True,\n",
    "                    \"filterable\": True,\n",
    "                    \"retrievable\": True,\n",
    "                    \"sortable\": False,\n",
    "                    \"facetable\": False,\n",
    "                    \"key\": True,\n",
    "                    \"indexAnalyzer\": None,\n",
    "                    \"searchAnalyzer\": None,\n",
    "                    \"analyzer\": \"keyword\",\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"chunk\",\n",
    "                    \"type\": \"Edm.String\",\n",
    "                    \"searchable\": True,\n",
    "                    \"filterable\": False,\n",
    "                    \"retrievable\": True,\n",
    "                    \"sortable\": False,\n",
    "                    \"facetable\": False,\n",
    "                    \"key\": False,\n",
    "                    \"analyzer\": \"standard.lucene\",\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"parent_key\",\n",
    "                    \"type\": \"Edm.String\",\n",
    "                    \"searchable\": False,\n",
    "                    \"filterable\": True,\n",
    "                    \"retrievable\": True,\n",
    "                    \"sortable\": False,\n",
    "                    \"facetable\": False,\n",
    "                    \"key\": False,\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"embedding\",\n",
    "                    \"type\": \"Collection(Edm.Single)\",\n",
    "                    \"searchable\": True,\n",
    "                    \"filterable\": False,\n",
    "                    \"retrievable\": True,\n",
    "                    \"sortable\": False,\n",
    "                    \"facetable\": False,\n",
    "                    \"key\": False,\n",
    "                    \"dimensions\": embedding_dims,\n",
    "                    \"vectorSearchProfile\": self.vector_search_profile,\n",
    "                    \"synonymMaps\": [],\n",
    "                },\n",
    "            ],\n",
    "            \"scoringProfiles\": [],\n",
    "            \"corsOptions\": None,\n",
    "            \"suggesters\": [],\n",
    "            \"analyzers\": [],\n",
    "            \"normalizers\": [],\n",
    "            \"tokenizers\": [],\n",
    "            \"tokenFilters\": [],\n",
    "            \"charFilters\": [],\n",
    "            \"encryptionKey\": None,\n",
    "            \"similarity\": {\n",
    "                \"@odata.type\": \"#Microsoft.Azure.Search.BM25Similarity\",\n",
    "                \"k1\": None,\n",
    "                \"b\": None,\n",
    "            },\n",
    "            \"semantic\": {\n",
    "                \"defaultConfiguration\": None,\n",
    "                \"configurations\": [\n",
    "                    {\n",
    "                        \"name\": self.semantic_config,\n",
    "                        \"prioritizedFields\": {\n",
    "                            \"titleField\": None,\n",
    "                            \"prioritizedContentFields\": [{\"fieldName\": \"chunk\"}],\n",
    "                            \"prioritizedKeywordsFields\": [\n",
    "                                {\"fieldName\": \"id\"},\n",
    "                                {\"fieldName\": \"parent_key\"},\n",
    "                            ],\n",
    "                        },\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            \"vectorSearch\": {\n",
    "                \"algorithms\": [\n",
    "                    {\n",
    "                        \"name\": self.vector_search_config,\n",
    "                        \"kind\": \"hnsw\",\n",
    "                        \"hnswParameters\": {\n",
    "                            # use cosine similarity when using OpenAI models,\n",
    "                            # else use the distance metric of the embedding model\n",
    "                            \"metric\": \"cosine\",\n",
    "                            \"m\": 4,  # bi-directional link count\n",
    "                            \"efConstruction\": 400,  # number of nearest neighbors to consider during indexiing\n",
    "                            \"efSearch\": 500,  # number of nearest neighbors to consider during search\n",
    "                        },\n",
    "                        \"exhaustiveKnnParameters\": None,\n",
    "                    }\n",
    "                ],\n",
    "                \"profiles\": [\n",
    "                    {\n",
    "                        \"name\": self.vector_search_profile,\n",
    "                        \"algorithm\": self.vector_search_config,\n",
    "                        \"vectorizer\": self.vector_search_vectorizer,\n",
    "                    }\n",
    "                ],\n",
    "                \"vectorizers\": [\n",
    "                    {\n",
    "                        \"name\": self.vector_search_vectorizer,\n",
    "                        \"kind\": \"azureOpenAI\",\n",
    "                        \"azureOpenAIParameters\": {\n",
    "                            \"resourceUri\": model_uri,\n",
    "                            \"deploymentId\": model_name,\n",
    "                            \"apiKey\": model_api_key,\n",
    "                            \"authIdentity\": None,\n",
    "                        },\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "        }\n",
    "        return index_payload\n",
    "\n",
    "    def create_index(self, index_type=\"search\", **kwargs):\n",
    "        if self.check_data_source_exists():\n",
    "            if index_type == \"search\":\n",
    "                index_payload = self.create_search_index_payload()\n",
    "            elif index_type == \"vector\":\n",
    "                index_payload = self.create_vector_index_payload(**kwargs)\n",
    "            response = requests.post(\n",
    "                f\"https://{self.search_service}.search.windows.net/indexes?api-version={self.api_version}\",\n",
    "                headers=self.headers,\n",
    "                json=index_payload,\n",
    "            )\n",
    "            if response.status_code == 201:\n",
    "                self.index = response.json()\n",
    "                return True\n",
    "            else:\n",
    "                logging.error(f\"{response.status_code} || {response.json()}\")\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def create_skillset(self, model_uri, model_name, model_api_key):\n",
    "        \"\"\"\n",
    "        Create a skillset for the indexer\n",
    "        This skillset will be used to enrich the content before indexing\n",
    "        \"\"\"\n",
    "        if self.vector_skillset_name:\n",
    "            skillset_payload = {\n",
    "                \"name\": self.vector_skillset_name,\n",
    "                \"description\": \"skills required for vector embedding creation processing\",\n",
    "                \"skills\": [\n",
    "                    {\n",
    "                        \"@odata.type\": \"#Microsoft.Skills.Text.SplitSkill\",\n",
    "                        \"name\": \"text-chunking-skill\",\n",
    "                        \"description\": \"Skillset to describe the Text chunking required for vectorization\",\n",
    "                        \"context\": \"/document\",\n",
    "                        \"defaultLanguageCode\": \"en\",\n",
    "                        \"textSplitMode\": \"pages\",\n",
    "                        \"maximumPageLength\": 2000,\n",
    "                        \"pageOverlapLength\": 500,\n",
    "                        \"maximumPagesToTake\": 0,\n",
    "                        \"inputs\": [{\"name\": \"text\", \"source\": \"/document/content\"}],\n",
    "                        \"outputs\": [{\"name\": \"textItems\", \"targetName\": \"chunks\"}],\n",
    "                    },\n",
    "                    {\n",
    "                        \"@odata.type\": \"#Microsoft.Skills.Text.AzureOpenAIEmbeddingSkill\",\n",
    "                        \"name\": \"embedding-generation-skill\",\n",
    "                        \"description\": \"\",\n",
    "                        \"context\": \"/document/chunks/*\",\n",
    "                        \"resourceUri\": model_uri,\n",
    "                        \"apiKey\": model_api_key,\n",
    "                        \"deploymentId\": model_name,\n",
    "                        \"inputs\": [{\"name\": \"text\", \"source\": \"/document/chunks/*\"}],\n",
    "                        \"outputs\": [{\"name\": \"embedding\", \"targetName\": \"embedding\"}],\n",
    "                    },\n",
    "                ],\n",
    "                \"indexProjections\": {\n",
    "                    \"selectors\": [\n",
    "                        {\n",
    "                            \"targetIndexName\": self.vector_index_name,\n",
    "                            \"parentKeyFieldName\": \"parent_key\",\n",
    "                            \"sourceContext\": \"/document/chunks/*\",\n",
    "                            \"mappings\": [\n",
    "                                {\n",
    "                                    \"name\": \"chunk\",\n",
    "                                    \"source\": \"/document/chunks/*\",\n",
    "                                    \"sourceContext\": None,\n",
    "                                    \"inputs\": [],\n",
    "                                },\n",
    "                                {\n",
    "                                    \"name\": \"embedding\",\n",
    "                                    \"source\": \"/document/chunks/*/embedding\",\n",
    "                                    \"sourceContext\": None,\n",
    "                                    \"inputs\": [],\n",
    "                                },\n",
    "                            ],\n",
    "                        }\n",
    "                    ],\n",
    "                    \"parameters\": {},\n",
    "                },\n",
    "            }\n",
    "            response = requests.post(\n",
    "                f\"https://{self.search_service}.search.windows.net/skillsets?api-version={self.api_version}\",\n",
    "                headers=self.headers,\n",
    "                json=skillset_payload,\n",
    "            )\n",
    "            if response.status_code == 201:\n",
    "                self.skillset = response.json()\n",
    "                return True\n",
    "            else:\n",
    "                logging.error(f\"{response.status_code} || {response.json()}\")\n",
    "                return False\n",
    "\n",
    "    def create_indexer(self, cache_storage_connection, batch_size=100):\n",
    "        if self.check_index_exists(self.search_index_name) and self.check_index_exists(\n",
    "            self.vector_index_name\n",
    "        ):\n",
    "            indexer_payload = {\n",
    "                \"name\": self.indexer_name,\n",
    "                \"description\": \"Indexer for Azure Blob storage container\",\n",
    "                \"dataSourceName\": self.data_source_name,\n",
    "                \"targetIndexName\": self.search_index_name,\n",
    "                \"skillsetName\": self.vector_skillset_name,\n",
    "                \"schedule\": {\"interval\": \"PT24H\", \"startTime\": \"2024-01-01T00:00:00Z\"},\n",
    "                \"parameters\": {\n",
    "                    \"configuration\": {\n",
    "                        \"indexedFileNameExtensions\": \".txt\",\n",
    "                        \"parsingMode\": \"text\",\n",
    "                        \"dataToExtract\": \"contentAndMetadata\",\n",
    "                    },\n",
    "                    \"batchSize\": batch_size,\n",
    "                },\n",
    "                \"cache\": {\n",
    "                    \"enableReprocessing\": True,\n",
    "                    \"storageConnectionString\": cache_storage_connection,\n",
    "                },\n",
    "            }\n",
    "            response = requests.post(\n",
    "                f\"https://{self.search_service}.search.windows.net/indexers?api-version={self.api_version}\",\n",
    "                headers=self.headers,\n",
    "                json=indexer_payload,\n",
    "            )\n",
    "            if response.status_code == 201:\n",
    "                self.indexer = response.json()\n",
    "                return True\n",
    "            else:\n",
    "                logging.error(f\"{response.status_code} || {response.json()}\")\n",
    "                return False\n",
    "        else:\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_indexer = AISearchIndexer(\n",
    "            search_service=SEARCH_SERVICE,\n",
    "            data_source_name=SEARCH_DATASOURCE_NAME,\n",
    "            search_index_name=SEARCH_INDEX_NAME,\n",
    "            vector_index_name=VECTOR_INDEX_NAME,\n",
    "            indexer_name=SEARCH_INDEXER_NAME,\n",
    "            vector_skillset_name=VECTOR_SKILLSET_NAME,\n",
    "            api_key=SEARCH_API_KEY,\n",
    "    )\n",
    "# Step 1 - Create the Data Source\n",
    "response = search_indexer.create_data_source_blob_storage(\n",
    "            blob_connection=STORAGE_CONNECTION,\n",
    "            blob_container_name=CONTAINER_NAME,\n",
    "            query=PROJECT_NAME,\n",
    ")\n",
    "logging.info(f\"Search Data Source status = {response}.\")\n",
    "# Step 2 - Create the Keyword Index\n",
    "response = search_indexer.create_index(index_type=\"search\")\n",
    "logging.info(f\"Keyword Search Index status = {response}.\")\n",
    "# Step 3 - Create the Vector Index (with embedding model)\n",
    "response = search_indexer.create_index(\n",
    "    index_type=\"vector\",\n",
    "    model_uri=VECTOR_EMBEDDING_URI,\n",
    "    model_name=VECTOR_EMBEDDING_ID,\n",
    "    model_api_key=VECTOR_EMBEDDING_API_KEY,\n",
    "    embedding_dims=VECTOR_EMBEDDING_DIMENSION,\n",
    ")\n",
    "logging.info(f\"Vector Search Index status = {response}.\")\n",
    "# Step 4 - Create the Vector embedding skillset to enhance the indexer\n",
    "response = search_indexer.create_skillset(\n",
    "    model_uri=VECTOR_EMBEDDING_URI,\n",
    "    model_name=VECTOR_EMBEDDING_ID,\n",
    "    model_api_key=VECTOR_EMBEDDING_API_KEY,\n",
    ")\n",
    "logging.info(f\"Vector Skillset status = {response}.\")\n",
    "# Step 5 - Create the indexer which will ultimately call the vector embedding skillset\n",
    "response = search_indexer.create_indexer(\n",
    "    cache_storage_connection=STORAGE_CONNECTION,\n",
    "    batch_size=SEARCH_INDEXER_BATCH_SIZE,\n",
    ")\n",
    "logging.info(f\"Search Indexer status = {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test quality of AI Search Context for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "import openai, os, requests\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "pp=pprint.PrettyPrinter()\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('OpenAI version = ', openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "# Azure OpenAI on your own data is only supported by the 2023-08-01-preview API version\n",
    "openai.api_version = \"2023-08-01-preview\"\n",
    "\n",
    "# Azure OpenAI setup\n",
    "openai.api_base = os.getenv(\"OPENAI_ENDPOINT_URI\") # Add your endpoint here\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") # Add your OpenAI API key here\n",
    "deployment_id = \"gpt-4\" # Add your deployment ID here\n",
    "\n",
    "# Azure AI Search setup\n",
    "search_endpoint = os.getenv(\"AI_SEARCH_ENDPOINT\"); # Add your Azure AI Search endpoint here\n",
    "search_key = os.getenv(\"AI_SEARCH_KEY\"); # Add your Azure AI Search admin key here\n",
    "search_index_name = \"telstra-vector-index\"; # Add your Azure AI Search index name here\n",
    "\n",
    "# Azure Embedding model endpoint\n",
    "embedding_endpoint = os.getenv(\"VECTOR_EMBEDDING_URI\")\n",
    "embedding_key = os.getenv(\"VECTOR_EMBEDDING_API_KEY\")\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an AI bot designed to answer questions about Telstra. \n",
    "You must respond only from the data source provided. \n",
    "If you do not know the answer, you can say 'I don't know'.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup_byod(deployment_id: str) -> None:\n",
    "    \"\"\"Sets up the OpenAI Python SDK to use your own data for the chat endpoint.\n",
    "\n",
    "    :param deployment_id: The deployment ID for the model to use with your own data.\n",
    "\n",
    "    To remove this configuration, simply set openai.requestssession to None.\n",
    "    \"\"\"\n",
    "\n",
    "    class BringYourOwnDataAdapter(requests.adapters.HTTPAdapter):\n",
    "\n",
    "        def send(self, request, **kwargs):\n",
    "            request.url = f\"{openai.api_base}/openai/deployments/{deployment_id}/extensions/chat/completions?api-version={openai.api_version}\"\n",
    "            return super().send(request, **kwargs)\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    # Mount a custom adapter which will use the extensions endpoint for any call using the given `deployment_id`\n",
    "    session.mount(\n",
    "        prefix=f\"{openai.api_base}/openai/deployments/{deployment_id}\",\n",
    "        adapter=BringYourOwnDataAdapter()\n",
    "    )\n",
    "\n",
    "    openai.requestssession = session\n",
    "\n",
    "setup_byod(deployment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PROMPT = [\n",
    "    {\"role\":\"system\", \"content\": SYSTEM_PROMPT},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_chat_history(chat_history):\n",
    "    for message in chat_history:\n",
    "        pp.pprint(f\"{message['role']}: {message['content']}\")\n",
    "\n",
    "def get_chat_response(chat_history,\n",
    "                      temperature=0.7,\n",
    "                        max_tokens=150,\n",
    "                        top_p=1,\n",
    "                        frequency_penalty=0,\n",
    "                        presence_penalty=0,\n",
    "                        seed=12345,\n",
    "                        topN=5,\n",
    "                        strictness=3,\n",
    "                        enforce_inscope=True,\n",
    "                        queryType=\"vector\", # simple, semantic, vectorSimpleHybrid, vectorSemanticHybrid\n",
    "                        roleInformation=SYSTEM_PROMPT,\n",
    "                      ):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        temperature=0.7,\n",
    "        messages=chat_history,\n",
    "        deployment_id=deployment_id,\n",
    "        dataSources=[  # camelCase is intentional, as this is the format the API expects\n",
    "            {\n",
    "                \"type\": \"AzureCognitiveSearch\",\n",
    "                \"parameters\": {\n",
    "                    \"endpoint\": search_endpoint,\n",
    "                    \"key\": search_key,\n",
    "                    \"indexName\": search_index_name,\n",
    "                    \"topNDocuments\": topN,\n",
    "                    \"inScope\": enforce_inscope,\n",
    "                    \"semanticConfiguration\": \"semantic-config-a0859498-994\",\n",
    "                    \"roleInformation\": roleInformation,\n",
    "                    \"strictness\": strictness,\n",
    "                    \"embeddingEndpoint\": embedding_endpoint,\n",
    "                    \"embeddingKey\": embedding_key,\n",
    "                    \"queryType\": queryType,\n",
    "                    \"fieldsMapping\": {\n",
    "                        \"contentFields\": [\n",
    "                            \"chunk\",\n",
    "                        ],\n",
    "                        # \"titleField\" : \"ADD TITLE TO INDEX\",\n",
    "                        # \"urlField\" : \"ADD URL TO INDEX\",\n",
    "                        # \"filepathField\" : \"ADD FILEPATH TO INDEX\",\n",
    "                    }\n",
    "\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from copy import deepcopy\n",
    "def get_user_input():\n",
    "    # initialize chat history\n",
    "    chat_history = deepcopy(BASE_PROMPT)\n",
    "    context_history = []\n",
    "    # Create text input widget\n",
    "    text_input = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='Type something',\n",
    "        description='User Input:',\n",
    "        disable=False\n",
    "    )\n",
    "\n",
    "    # Create a button widget for submitting\n",
    "    submit_button = widgets.Button(\n",
    "        description='Submit',\n",
    "        disable=False,\n",
    "        button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip='Submit',\n",
    "        icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    "    )\n",
    "\n",
    "    # Create a button widget for clearing\n",
    "    clear_button = widgets.Button(\n",
    "        description='Clear',\n",
    "        disable=False,\n",
    "        button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip='Clear',\n",
    "        icon='remove' # (FontAwesome names without the `fa-` prefix)\n",
    "    )\n",
    "\n",
    "    # Display the widgets\n",
    "    display(text_input, submit_button, clear_button)\n",
    "\n",
    "    # Function to handle the submit button click event\n",
    "    def on_submit_button_clicked(b):\n",
    "        # Get the text input\n",
    "        user_input = text_input.value\n",
    "\n",
    "        # construct the prompt\n",
    "        chat_history.append({\"role\":\"user\", \"content\": user_input})\n",
    "\n",
    "        # Pass the input to the get_chat_response function\n",
    "        start=time.time()\n",
    "        response = get_chat_response(chat_history)\n",
    "        # response = \"DUMMY RESPONSE\"\n",
    "        end=time.time()\n",
    "        # bot response\n",
    "        bot_response = response.choices[0]['message']['content']\n",
    "        context_history.append(response.choices[0]['message']['context']['messages'][0]['content'])\n",
    "\n",
    "        # append the bot response to the chat history\n",
    "        chat_history.append({\"role\":\"assistant\", \"content\": bot_response})\n",
    "\n",
    "        # print chat history\n",
    "        print_chat_history(chat_history)\n",
    "        pp.pprint(context_history)\n",
    "        pp.pprint(f\"Time taken: {end-start:.3} seconds\")\n",
    "\n",
    "    # Function to handle the clear button click event\n",
    "    def on_clear_button_clicked(b):\n",
    "        # Clear the output\n",
    "        clear_output(wait=False)\n",
    "        display(text_input, submit_button, clear_button)\n",
    "\n",
    "\n",
    "    # Attach the event handlers to the button widgets\n",
    "    submit_button.on_click(on_submit_button_clicked)\n",
    "    clear_button.on_click(on_clear_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_user_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_BANK = [\n",
    "    \"How do I check the expiry of my SIM card\",\n",
    "    \"From which year are the Telstra financial reports available?\",\n",
    "    \"How do I buy or sell Telstra shares?\",\n",
    "    \"Can sharehholders receive a discount o Telstra products. Answer in yes or no\",\n",
    "    \"What is Telstra's sustainability strategy?\",\n",
    "    \"How does Telstra work on Digital Literacy?\",\n",
    "    \"What does LIMAC stand for and how is it related to access for everyone?\",\n",
    "    \"Which edition of the ASX Corporate Governance Principles and Recommendations does Telstra follow?\",\n",
    "    \"When did Telstra Group become the new listed entity of the Telstra Corporation Limited?\",\n",
    "    \"How do I pay my bills on the My Telstra app? Answer in bullet point format in 1-2 sentences\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for qType in [\"vector\",\"simple\", \"semantic\",\"vectorSimpleHybrid\", \"vectorSemanticHybrid\"]:\n",
    "# for qType in [\"vectorSemanticHybrid\"]:\n",
    "    for q in QUESTION_BANK:\n",
    "        start = time.time()\n",
    "        chat_history = deepcopy(BASE_PROMPT)\n",
    "        chat_history.append({\"role\":\"user\", \"content\": q})\n",
    "        response = get_chat_response(chat_history, queryType=qType)\n",
    "        end=time.time()\n",
    "        bot_response = response.choices[0]['message']['content']\n",
    "        context_history = response.choices[0]['message']['context']['messages'][0]['content']\n",
    "        chat_history.append({\"role\":\"assistant\", \"content\": bot_response})\n",
    "        print_chat_history(chat_history)\n",
    "        pp.pprint(f\"Time taken: {end-start:.3} seconds\")\n",
    "        results.append([qType, q, bot_response, context_history, end-start])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['query_type'] != 'vectorSemanticHybrid']\n",
    "df2 = pd.DataFrame(results, columns = [\"query_type\", \"question\",\"response\",\"context\", \"time_taken\"])\n",
    "df = pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"query_type\").agg({\"time_taken\": [\"mean\", \"std\"]}).sort_values((\"time_taken\", \"mean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
